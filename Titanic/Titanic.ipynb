{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic in Machine Learning\nYutao Chen  \n04/05/2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib as plt\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepara the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain_len = len(train)\ntest_ID = test[\"PassengerId\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns.values)  # see all the titles of the data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see the general info about the data\ntrain.info()\nprint('-'*40)\ntest.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine training and testing for processing\nall_data = pd.concat(objs=[train, test], axis=0, sort=False).reset_index(drop=True)\nall_data = all_data.fillna(np.nan) # fill the all different kinds of missing data with NaN\nall_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.isnull().sum()  # see if there are some missing values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis and process the data column by colum"},{"metadata":{},"cell_type":"markdown","source":"## 1. Pclass"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Pclass\",y=\"Survived\",data=train,kind=\"bar\",palette = \"muted\")\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the people in first class have higher survival probability. While the people in third class have the lowest.   \nThere is no missing data for this column, so we don't need to fill missing data.   \nThe data type is int and is 1, 2 and 3. So we don't need to do anythin with the data.  "},{"metadata":{},"cell_type":"markdown","source":"## 2. Name"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Name (Title)\nall_data['Name'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only take the title in the name\ntitle = [i.split(\",\")[1].split(\".\")[0].strip() for i in all_data[\"Name\"]]\nall_data[\"Title\"] = pd.Series(title)\nall_data[\"Title\"].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show all the different titles\nall_data[\"Title\"].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see if there are any missing data\nall_data[\"Title\"].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=all_data)\ng = plt.pyplot.setp(g.get_xticklabels(), rotation=90)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the title as 0, 1, 2 and 3\n# All the title with very few people are grouped together\nall_data[\"Title\"] = all_data[\"Title\"].replace([\"Don\",\"Rev\",\"Dr\",\"Major\",\"Mlle\",\"Col\",\"Mme\",\n                                               \"Ms\",\"Lady\",\"Sir\",\"Capt\",\"the Countess\",\"Jonkheer\",\"Dona\"], 'Rare')\nall_data[\"Title\"] = all_data[\"Title\"].map({\"Mr\":0, \"Mrs\":1, \"Miss\" : 1 , \"Master\":2, \"Rare\":3})\nall_data[\"Title\"] = all_data[\"Title\"].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Title\",y=\"Survived\",data=all_data,kind=\"bar\")\ng = g.set_xticklabels([\"Mr\",\"Miss/Mrs\",\"Master\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# don't need the column \"Name\" \nall_data.drop(labels = [\"Name\"], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, the title in name tell us some about this people. Maybe people with some titles have higher probability to survive.  \n"},{"metadata":{},"cell_type":"markdown","source":"## 3. Sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sex\ng = sns.catplot(x=\"Sex\",y=\"Survived\",data=all_data,kind=\"bar\",palette = \"muted\")\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Sex\"] = all_data[\"Sex\"].map({\"male\": 0, \"female\":1})\nall_data[\"Sex\"] = all_data[\"Sex\"].astype(int)\nall_data[\"Sex\"].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Female have higher probability to survive in general.   \nThe only thing we need to do with \"Sex\" is to encode it into 0 and 1.  "},{"metadata":{},"cell_type":"markdown","source":"## 4. Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"# See which kind of the info is related to the age\n# I choose sex, SibSp, Parch, Pclass and Title as candidates\ng = sns.heatmap(all_data[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Title\"]].corr(),cmap=\"coolwarm\",annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill all the missing data\nNan_index_age = list(all_data[\"Age\"][all_data[\"Age\"].isnull()].index)  # index of missing data\n\nfor i in Nan_index_age:\n    median = all_data[\"Age\"].median()\n    # the median of all the data with similiar background\n    predict = all_data[\"Age\"][((all_data['SibSp'] == all_data.iloc[i][\"SibSp\"]) & \n                              (all_data['Parch'] == all_data.iloc[i][\"Parch\"]) & \n                              (all_data['Pclass'] == all_data.iloc[i][\"Pclass\"]) &\n                              (all_data['Title'] == all_data.iloc[i][\"Title\"]))].median()\n    if np.isnan(predict):\n        all_data['Age'].iloc[i] = median\n    else:\n        all_data['Age'].iloc[i] = predict\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Age'].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Survived\", y = \"Age\",data = all_data, kind=\"violin\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important thing is to find a way to fill the missing data in this columne.  \nI used the median number of ages of people with similiar background.  \nIf there is no median number, we use the overall average age.  \nThe people at age 0-5 have a relatively high probability to survive.  "},{"metadata":{},"cell_type":"markdown","source":"## 5. SibSp"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\",palette = \"muted\")\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People have 1 or 2 SibSp have higher survival probability"},{"metadata":{},"cell_type":"markdown","source":"## 6. Parch"},{"metadata":{"trusted":true},"cell_type":"code","source":"g  = sns.catplot(x=\"Parch\",y=\"Survived\",data=train,kind=\"bar\",palette = \"muted\")\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People have 1, 2 or 3 Parch have higher survival probability"},{"metadata":{},"cell_type":"markdown","source":"## 7. Ticket"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Ticket'].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take the prefix of the ticket to represent different kind of ticket\n# If the ticket is all number, I use \"Num\" to represent\nTicket = []\nfor i in list(all_data.Ticket):\n    if i.isdigit():\n        Ticket.append('Num')\n    else:\n        Ticket.append(i.replace(\".\",\"\").strip().split(\" \")[0])\nall_data[\"Ticket\"] = Ticket\nall_data[\"Ticket\"].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Fare\"] = all_data[\"Fare\"].fillna(all_data[\"Fare\"].median())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.distplot(all_data[\"Fare\"], color=\"g\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Fare\"] = all_data[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\ng = sns.distplot(all_data[\"Fare\"], color=\"g\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wide range of the data may reduce the accuracy. So, we take the log to narrow the range."},{"metadata":{},"cell_type":"markdown","source":"## 9. Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Cabin'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Cabin'].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'X' to represent NaN\n# Use the first character to represent the other\nall_data[\"Cabin\"] = all_data[\"Cabin\"].map(lambda i: 'X' if pd.isnull(i) else i[0])\nall_data['Cabin'].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Cabin'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(y=\"Survived\",x=\"Cabin\",data=all_data,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Cabin\"].unique()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only thing we need to do is to fill the missing data.  \nSince there are too many missing data, I decide not to predict, just treat it as another class.   "},{"metadata":{},"cell_type":"markdown","source":"## 10. Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Embarked\"].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Embarked\"].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fille the missing data\n# Only two missing data. So, just use the most common one\nall_data[\"Embarked\"] = all_data[\"Embarked\"].fillna(\"S\")\nall_data[\"Embarked\"].isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"Embarked\"].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the dato as 0, 1 and 2\nall_data[\"Embarked\"] = all_data[\"Embarked\"].map({\"S\":0, \"C\":1, \"Q\":2})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overview the data after the process"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creat categorical value for data with character value\nall_data = pd.get_dummies(all_data, columns = [\"Ticket\"], prefix=\"T\")\nall_data = pd.get_dummies(all_data, columns = [\"Cabin\"], prefix=\"C\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"## 1. Separat the data as training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = all_data[:train_len]\ntest_data = all_data[train_len:]\n\ntest_info = test_data.drop(labels=[\"Survived\"],axis = 1)\n\ntrain_label = train_data[\"Survived\"].astype(int)\ntrain_info = train_data.drop(labels = [\"Survived\"],axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The # of training data: {}\".format(train_label.shape[0]))\nprint(\"The # of training data: {}\\nThe dimension of training data: {}\".format(train_info.shape[0],train_info.shape[1]))\nprint(\"The # of testing data: {}\\nThe dimension of testing data: {}\".format(test_info.shape[0],test_info.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Define the Classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = []\nclassifiers.append(SVC(random_state = 2))\nclassifiers.append(AdaBoostClassifier(random_state = 2))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(MLPClassifier(random_state = 2))\nclassifiers.append(RandomForestClassifier(random_state = 2))\nclassifiers.append(DecisionTreeClassifier(random_state = 2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate and fit the classifiers\nresult = []\nfor i in classifiers:\n    result.append(cross_val_score(i, train_info, y = train_label, scoring = \"accuracy\", cv = kfold, n_jobs=1))\n    i = i.fit(train_info, train_label)\nmeans = []\nfor i in result:\n    means.append(i.mean())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame({\"Means\":means,\"Methods\":['SVC','AdaBoost','KNeighbors','LDA',\n                                             'MLP','RandomForest','DecisionTree']})\ng = sns.barplot(\"Means\",\"Methods\",data = res, palette=\"muted\")\ntitle = g.set_xlabel(\"Mean Accuracy\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the classifier's accuracy is around 0.8. So, we can use all of them."},{"metadata":{},"cell_type":"markdown","source":"## 3. predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts = np.empty((7,418))\nrow = 0\nfor i in classifiers:\n    predicts[row,:] = i.predict(test_info)\n    row += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predicts.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate the final result"},{"metadata":{"trusted":true},"cell_type":"code","source":"res = []\nfor col in range(418):\n    mean = np.mean(predicts[:,col])\n    res.append(0 if mean <= 0.5 else 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Generate the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.Series(res, name=\"Survived\")\nsubmit = pd.concat([test_ID,result],axis=1)\nsubmit.to_csv(\"submission.csv\",index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}