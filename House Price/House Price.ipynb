{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ML on House Pricing\n## Yutao Chen\n## 04/15/2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import norm\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preapre the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nSalePrice = train['SalePrice']  # Separate the column \"SalePrice\"\ntrain_len = len(train) # the length og training data\nprint(\"The dimensions of training data is: {}\".format(train.shape))\nprint(\"The dimensions of testing data is: {}\".format(test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat(objs=[train, test], axis=0, sort=False).reset_index(drop=True)  # combine the data\nall_data = all_data.fillna(np.nan) # fill the all different kinds of missing data with NaN\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choose features (Numerical)\nIn this part, we deal eoth the numerical data. We first see how these data are related to the sal price then we only keep the most related few as training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(12, 9))\ng = sns.heatmap(train.corr(),cmap=\"coolwarm\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the pllt that the following data are closely related to sale price compared to others.  \n\nThey are:    \n\"SalePrice\", \"OverallQual\", \"GrLivArea\", \"TotalBsmtSF\", \"1stFlrSF\", \"GarageCars\", \"GarageArea\", \"YearBuilt\", \"FullBath\", \"TotRmsAbvGrd\",\"LotFrontage\", \"YearRemodAdd\", \"MasVnrArea\", \"BsmtFinSF1\",\"Fireplaces\",\"GarageYrBlt\"\n\nSo we zoom in the plot to conduct a second choose."},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.heatmap(train[[\"SalePrice\", \"OverallQual\", \"GrLivArea\", \n                       \"TotalBsmtSF\", \"1stFlrSF\", \"GarageCars\", \n                       \"GarageArea\", \"YearBuilt\", \"FullBath\", \n                       \"TotRmsAbvGrd\",\"LotFrontage\", \"YearRemodAdd\", \n                       \"MasVnrArea\", \"BsmtFinSF1\",\"Fireplaces\",\"GarageYrBlt\"]].corr(),\n                cmap=\"coolwarm\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.pairplot(train[[\"SalePrice\", \"OverallQual\", \"GrLivArea\", \"TotalBsmtSF\", \n                        \"GarageCars\", \"YearBuilt\", \"FullBath\", ]], height = 2.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final choice are made as follows: \"OverallQual\", \"GrLivArea\", \"TotalBsmSF\", \"GarageCars\", \"FullBath\", \"YearBuilt\"  \nOther abandoned data are either noe so related to sale price or highly related to one of the chosen data"},{"metadata":{},"cell_type":"markdown","source":"## Deal with chosen features (Numerical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"SalePrice\", \"OverallQual\", \"GrLivArea\", \"TotalBsmtSF\", \n       \"GarageCars\", \"YearBuilt\", \"FullBath\", ]].isnull().sum().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing data in these features, so we don't need to do anything!"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_feature = [\"OverallQual\", \"GrLivArea\", \"TotalBsmtSF\", \"GarageCars\", \"YearBuilt\", \"FullBath\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choose features (Categorical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"total = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_count = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_count.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We simply abandone the features that have more than 15% missing data\n\nThe features begin with \"Garage\" are highly related to the feature \"GarageCars\" which is already considered in numerical feature. So we simple abandone these features. So as features begin with \"Bsmt\" and \"MasVnr\"\n\nThus the only feature we care and with missing data is \"Electrical\""},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = all_data.drop((missing_count[missing_count['Total'] > 1]).index,1)\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0]) # since there is only one missing, we fill it with omst common data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate new data set (only have chosen features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = all_data.select_dtypes(include='object')  # Categorical features\nfor f in selected_feature:\n    new_data[f] = all_data[f]  # Numerical features\nnew_data.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.isnull().sum().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are still some missing data in the test set. So we need to fill them."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data['MSZoning'] = new_data['MSZoning'].fillna(new_data['MSZoning'].mode()[0])\nnew_data['Utilities'] = new_data['Utilities'].fillna(new_data['Utilities'].mode()[0])\nnew_data['Functional'] = new_data['Functional'].fillna(new_data['Functional'].mode()[0])\nnew_data['TotalBsmtSF'] = new_data['TotalBsmtSF'].fillna(0)\nnew_data['Exterior1st'] = new_data['Exterior1st'].fillna(new_data['Exterior1st'].mode()[0])\nnew_data['Exterior2nd'] = new_data['Exterior2nd'].fillna(new_data['Exterior1st'].mode()[0])\nnew_data['GarageCars'] = new_data['GarageCars'].fillna(0.0)\nnew_data['SaleType'] = new_data['SaleType'].fillna(new_data['SaleType'].mode()[0])\nnew_data['KitchenQual'] = new_data['KitchenQual'].fillna(new_data['KitchenQual'].mode()[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.isnull().sum().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in new_data.dtypes[new_data.dtypes == 'object'].index:\n    new_data[col] = new_data[col].astype('category')  # converting to a category dtype\n    new_data[col] = new_data[col].cat.codes\nprint(new_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data=(new_data-new_data.mean())/new_data.std()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"new_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SalePrice Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"SalePrice.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.distplot(SalePrice, fit=norm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Skewness : {}'.format(SalePrice.skew()))\nprint('Kurtosis : {}'.format(SalePrice.kurt()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A more normal distributed data will be beneficial to our training"},{"metadata":{"trusted":true},"cell_type":"code","source":"SalePrice = np.log(SalePrice)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.distplot(SalePrice, fit=norm);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the data is more \"Normal\" than the original data"},{"metadata":{},"cell_type":"markdown","source":"## Data for Training\nHere we prepare the data for training and predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_info = new_data[:train_len]\ntrain_label = SalePrice\ntrain = pd.concat([train_info, train_label], axis=1, sort=False)\n\ntest_info = new_data[train_len:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train_info.values, train_label.values, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define models"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=42))\n\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.8, random_state=3))\n\nKR = KernelRidge(alpha=6, kernel='polynomial', degree=2, coef0=2.5)\n\nGBoost = GradientBoostingRegressor(n_estimators=2000, learning_rate=0.05, max_depth=4, \n                                   max_features='sqrt',min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber',random_state =5)\n\nXGBoost = XGBRegressor(n_estimators=2000, learning_rate=0.05, random_state =7)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See the score for different models"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(KR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(XGBoost)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{},"cell_type":"markdown","source":"I choose the GBoost as final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"GBoost.fit(train_info, train_label)\nres = GBoost.predict(test_info)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we take the natural log of the \"Saleprice\", we need to undo that."},{"metadata":{"trusted":true},"cell_type":"code","source":"res = np.expm1(res)\nprint(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pd.DataFrame(res, columns=['SalePrice'])\nresult = pd.concat([test['Id'], prediction], axis=1)\nresult.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}